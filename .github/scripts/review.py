import os
import asyncio
from github import Github
import google.generativeai as genai
from openai import OpenAI
from anthropic import Anthropic
from dataclasses import dataclass

# --- CONFIGè¨­å®šã‚¯ãƒ©ã‚¹ã®å®šç¾© ---
@dataclass(frozen=True)
class ReviewConfig:
    gemini_model: str
    gpt_model: str
    claude_model: str
    summarizer_model: str
    small_diff_threshold: int
    flash_only_max_tokens: int

# --- CONFIGã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä½œæˆï¼ˆèª­ã¿è¾¼ã¿ï¼‰ ---
CONFIG = ReviewConfig(
    gemini_model=os.getenv("GEMINI_MODEL", "gemini-2.5-flash"),
    gpt_model=os.getenv("GPT_MODEL", "gpt-4o"),
    claude_model=os.getenv("CLAUDE_MODEL", "claude-sonnet-4-5"),
    summarizer_model=os.getenv("SUMMARIZER_MODEL", "gemini-2.5-pro"),

    small_diff_threshold=int(os.getenv("SMALL_DIFF_THRESHOLD", 30000)),
    flash_only_max_tokens=int(os.getenv("FLASH_ONLY_MAX_TOKENS", 300000))
)

# AIã®å½¹å‰²ã¨æŒ‡ç¤ºã‚’å®šç¾©ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
SYSTEM_PROMPT = """
ã‚ãªãŸã¯çµŒé¨“10å¹´ä»¥ä¸Šã®å³æ ¼ãªã‚·ãƒ‹ã‚¢ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
ã‚ãªãŸã®ä»•äº‹ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰å·®åˆ†ï¼ˆDiffï¼‰ã‚’å¾¹åº•çš„ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã®å“è³ªã‚’æœ€é«˜ãƒ¬ãƒ™ãƒ«ã«ä¿ã¤ã“ã¨ã§ã™ã€‚

ã€é‡è¦æŒ‡ç¤ºã€‘
1.  æŒ‡æ‘˜äº‹é …ã¯ã€**ãƒ•ã‚¡ã‚¤ãƒ«å**ã¨**ã‚»ã‚¯ã‚·ãƒ§ãƒ³**ã‚’æ˜ç¢ºã«ã—ãŸä¸Šã§ã€Markdownã®ç®‡æ¡æ›¸ãã§å¿…ãšå‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
2.  å…·ä½“çš„ãªæ”¹å–„æ¡ˆã¯ã€ç°¡æ½”ãªã‚³ãƒ¼ãƒ‰ä¾‹ã‚’æ·»ãˆã¦ãã ã•ã„ã€‚
3.  æŒ‡æ‘˜ãŒãªã„å ´åˆã¯ã€ã€ŒæŒ‡æ‘˜äº‹é …ãªã—ã€ã“ã®PRã¯å³ãƒãƒ¼ã‚¸OKã§ã™ã€ã¨ã ã‘å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼é‡ç‚¹é …ç›®ã€‘
* **ãƒã‚°**ï¼šè«–ç†çš„ãªèª¤ã‚Šã€äºˆæœŸã›ã¬ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã€ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å‡¦ç†ã®æ¼ã‚Œã€‚
* **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**ï¼šæ½œåœ¨çš„ãªè„†å¼±æ€§ï¼ˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã€æƒ…å ±æ¼æ´©ã€èªå¯ã®æ¬ å¦‚ãªã©ï¼‰ã€‚
* **ä¿å®ˆæ€§**ï¼šã‚³ãƒ¼ãƒ‰ã®è¤‡é›‘æ€§ï¼ˆå¾ªç’°çš„è¤‡é›‘åº¦ãŒé«˜ã„éƒ¨åˆ†ï¼‰ã€å°†æ¥ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ãŒå¿…è¦ãªè¨­è¨ˆä¸Šã®å•é¡Œã€‚
* **å¯èª­æ€§**ï¼šå‘½åè¦å‰‡ã®é•åã€ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã®ä½¿ç”¨ã€ã‚³ãƒ¡ãƒ³ãƒˆä¸è¶³ã€‚
"""

# GitHubã®è¨­å®š
g = Github(os.getenv("GITHUB_TOKEN"))
repo = g.get_repo(os.getenv("GITHUB_REPOSITORY"))
pr_number = int(os.getenv("GITHUB_REF").split("/")[-2])
pr = repo.get_pull(pr_number)

# å¤‰æ›´å·®åˆ†(Diff)ã®å–å¾—
def get_diff():
    return pr.get_files()

def check_diff_size(diff_text):
    # ç°¡å˜ãªãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ¦‚ç®— (æ–‡å­—æ•°/3ã§è¿‘ä¼¼)
    token_count = len(diff_text) // 3

    if token_count > CONFIG.flash_only_max_tokens:
        pr.create_issue_comment(
            f"ğŸš¨ **è­¦å‘Š: DIFFã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ (ç´„ {token_count} ãƒˆãƒ¼ã‚¯ãƒ³)**\n"
            "AIãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ç²¾åº¦ã¨ã‚³ã‚¹ãƒˆæŠ‘åˆ¶ã®ãŸã‚ã€æ‰‹å‹•ã§ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"
        )
        return False, token_count
    return True, token_count

# å„AIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–¢æ•°
async def ask_gemini(diff_text):
    try:
        genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
        model = genai.GenerativeModel(
                CONFIG.gemini_model,
                system_instruction=SYSTEM_PROMPT
            )
        response = model.generate_content(f"ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰å·®åˆ†ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„:\n---\n{diff_text}\n---")
        return f"## â™Š Gemini\n{response.text}"
    except Exception as e:
        return f"## â™Š Gemini (Error)\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

async def ask_gpt4o(diff_text):
    try:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        response = client.chat.completions.create(
            model=CONFIG.gpt_model,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": f"ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰å·®åˆ†ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„:\n---\n{diff_text}\n---"}
            ]
        )
        return f"## ğŸ¤– ChatGPT\n{response.choices[0].message.content}"
    except Exception as e:
        return f"## ğŸ¤– ChatGPT (Error)\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

async def ask_claude(diff_text):
    try:
        client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        message = client.messages.create(
            model=CONFIG.claude_model,
            max_tokens=2048,
            system=SYSTEM_PROMPT,
            messages=[
                {"role": "user", "content": f"ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰å·®åˆ†ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„:\n---\n{diff_text}\n---"}
            ]
        )
        return f"## ğŸ§  Claude\n{message.content[0].text}"
    except Exception as e:
        return f"## ğŸ§  Claude (Error)\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

async def summarize_reviews(all_results):
    try:
        genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
        model_name = CONFIG.summarizer_model

        summarizer_model = genai.GenerativeModel(
            model_name,
            system_instruction="ã‚ãªãŸã¯ã€è¤‡æ•°ã®AIãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã®æ„è¦‹ã‚’çµ±åˆã—ã€æœ€ã‚‚é‡è¦ã§å„ªå…ˆåº¦ã®é«˜ã„æŒ‡æ‘˜äº‹é …ã ã‘ã‚’ã€é‡è¤‡ãªãä¸€ã¤ã®Markdownãƒªã‚¹ãƒˆã«ã¾ã¨ã‚ã‚‹ç·¨é›†é•·ã§ã™ã€‚ãƒˆãƒ¼ãƒ³ã¯å³ã—ãã€å†—é•·ãªè¡¨ç¾ã¯å…¨ã¦å‰Šé™¤ã—ã¦ãã ã•ã„ã€‚"
        )

        # 3ã¤ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’çµåˆ
        combined_text = "\n\n---\n\n".join(all_results)

        user_prompt = f"""ä»¥ä¸‹ã®3ã¤ã®AIãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’çµ±åˆã—ã€é‡è¤‡ã‚’æ’é™¤ã—ã€å…·ä½“çš„ãªæŒ‡æ‘˜ã‚’å„ªå…ˆåº¦é †ã«å†æ§‹æˆã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã€3ã¤ã®AIãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã€‘
---
{combined_text}
---
"""
        response = summarizer_model.generate_content(user_prompt)

        return f"# ğŸ‘‘ çµ±åˆAIãƒ¬ãƒ“ãƒ¥ãƒ¼ (by {model_name})\n\n{response.text}"

    except Exception as e:
        return f"# ğŸ‘‘ çµ±åˆAIãƒ¬ãƒ“ãƒ¥ãƒ¼ (Error)\nçµ±åˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\n\n" + "\n\n---\n\n".join(all_results)

def create_final_comment(summary_report: str, individual_results: list[str]) -> str:
    final_comment = summary_report
    individual_section_content = "## ğŸ“„ å€‹åˆ¥AIãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœ (ç”Ÿã®å‡ºåŠ›)\n"
    individual_section_content += "ã“ã‚Œã‚‰ã®çµæœã‚’çµ±åˆAIãŒã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚çµ±åˆçµæœã«ä¸å‚™ãŒã‚ã‚‹å ´åˆã«ã”å‚ç…§ãã ã•ã„ã€‚\n\n"
    individual_section_content += "\n\n---\n\n".join(individual_results)
    collapsible_section = f"""
<details>
<summary>å€‹åˆ¥AIã®ç”Ÿãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’è¦‹ã‚‹ (ã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹)</summary>

{individual_section_content}

</details>
"""
    final_comment += "\n\n" + collapsible_section
    return final_comment

async def select_and_run_models(diff_text: str, token_count: int) -> list[str]:
    """
    DIFFã‚µã‚¤ã‚ºã«åŸºã¥ãã€æœ€é©ãªAIãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã€éåŒæœŸã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    """
    if token_count <= CONFIG.small_diff_threshold:
        # é«˜æ€§èƒ½ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ3ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ï¼‰
        print("INFO: 3ã¤ã®AIãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ä¸¦åˆ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œä¸­...")
        return await asyncio.gather(
            ask_gemini(diff_text),
            ask_gpt4o(diff_text),
            ask_claude(diff_text),
            return_exceptions=True
        )

    elif token_count <= CONFIG.flash_only_max_tokens:
        # ã‚³ã‚¹ãƒˆå„ªå…ˆãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆGemini Flashã®ã¿ä½¿ç”¨ï¼‰
        print(f"INFO: DIFFã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚ ({token_count} tokens)ã€Gemini Flashã®ã¿ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
        pr.create_issue_comment(
            f"âš ï¸ **DIFFã‚µã‚¤ã‚º ({token_count} ãƒˆãƒ¼ã‚¯ãƒ³) ã®ãŸã‚ã€Geminiã®ã¿ã§ã‚³ã‚¹ãƒˆå„ªå…ˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿæ–½ã—ã¾ã™ã€‚**"
        )
        results_raw = [await ask_gemini(diff_text)]

    else:
        return []

    results = [r for r in results_raw if not isinstance(r, Exception)]

    # å…¨ã¦ã®AIãŒå¤±æ•—ã—ãŸå ´åˆã®å‡¦ç†
    if not results:
        pr.create_issue_comment("ğŸš¨ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: å…¨ã¦ã®AIã‚µãƒ¼ãƒ“ã‚¹ã¸ã®æ¥ç¶šãŒå¤±æ•—ã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ã¾ãŸã¯ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return []

    return results


# ãƒ¡ã‚¤ãƒ³å‡¦ç†
async def main():
    files = get_diff()
    diff_text = ""
    for file in files:
        if file.filename.endswith(('.lock', '.png', '.jpg', '.svg')): continue
        if not file.patch:
             continue
        diff_text += f"File: {file.filename}\nDiff:\n{file.patch}\n\n"

    if not diff_text:
        print("å¤‰æ›´å·®åˆ†ãŒæ¤œå‡ºã•ã‚Œãªã„ãŸã‚ã€å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return

    is_ok, token_count = check_diff_size(diff_text)
    if not is_ok: return

    results = await select_and_run_models(diff_text, token_count)

    # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå®Ÿè¡Œã§ããªã‹ã£ãŸå ´åˆçµ‚äº†
    if not results:
        return

    print("INFO: ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã®çµ±åˆå‡¦ç†ã‚’å®Ÿè¡Œä¸­...")
    summary_report = await summarize_reviews(results)

    final_comment = create_final_comment(summary_report, results)

    # éå»ã®ãƒœãƒƒãƒˆã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯
    print("INFO: æ—¢å­˜ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤ä¸­...")
    comments = pr.get_issue_comments()
    HEADER_IDENTIFIER = "# ğŸ‘‘ çµ±åˆAIãƒ¬ãƒ“ãƒ¥ãƒ¼"

    for comment in comments:
        if comment.body and HEADER_IDENTIFIER in comment.body:
            try:
                comment.delete()
            except Exception as e:
                print(f"WARN: ã‚³ãƒ¡ãƒ³ãƒˆå‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ (ç„¡è¦–): {e}")

    # ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿
    pr.create_issue_comment(final_comment)
    print("SUCCESS: ãƒ¬ãƒ“ãƒ¥ãƒ¼å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    asyncio.run(main())

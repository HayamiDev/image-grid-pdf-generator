import sys
import os
import asyncio
from github import Github
import google.generativeai as genai
from openai import OpenAI
from anthropic import Anthropic
from dataclasses import dataclass
import json
import re
from google.generativeai.errors import APIError

# --- CONFIGè¨­å®šã‚¯ãƒ©ã‚¹ã®å®šç¾© ---
@dataclass(frozen=True)
class ReviewConfig:
    gemini_model: str
    gpt_model: str
    claude_model: str
    summarizer_model: str
    small_diff_threshold: int
    flash_only_max_tokens: int

# --- CONFIGã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä½œæˆï¼ˆèª­ã¿è¾¼ã¿ï¼‰ ---
CONFIG = ReviewConfig(
    gemini_model=os.getenv("GEMINI_MODEL", "gemini-2.5-flash"),
    gpt_model=os.getenv("GPT_MODEL", "gpt-4o"),
    claude_model=os.getenv("CLAUDE_MODEL", "claude-sonnet-4-5"),
    summarizer_model=os.getenv("SUMMARIZER_MODEL", "gemini-2.5-pro"),

    small_diff_threshold=int(os.getenv("SMALL_DIFF_THRESHOLD", 30000)),
    flash_only_max_tokens=int(os.getenv("FLASH_ONLY_MAX_TOKENS", 300000))
)

# AIã®å½¹å‰²ã¨æŒ‡ç¤ºã‚’å®šç¾©ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
SYSTEM_PROMPT = """
ã‚ãªãŸã¯çµŒé¨“10å¹´ä»¥ä¸Šã®å³æ ¼ãªã‚·ãƒ‹ã‚¢ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
ã‚ãªãŸã®ä»•äº‹ã¯ã€ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰å·®åˆ†ï¼ˆDiffï¼‰ã‚’å¾¹åº•çš„ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã®å“è³ªã‚’æœ€é«˜ãƒ¬ãƒ™ãƒ«ã«ä¿ã¤ã“ã¨ã§ã™ã€‚

ã€é‡è¦æŒ‡ç¤ºã€‘
1.  æŒ‡æ‘˜äº‹é …ã¯ã€**ãƒ•ã‚¡ã‚¤ãƒ«å**ã¨**ã‚»ã‚¯ã‚·ãƒ§ãƒ³**ã‚’æ˜ç¢ºã«ã—ãŸä¸Šã§ã€Markdownã®ç®‡æ¡æ›¸ãã§å¿…ãšå‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
2.  å…·ä½“çš„ãªæ”¹å–„æ¡ˆã¯ã€ç°¡æ½”ãªã‚³ãƒ¼ãƒ‰ä¾‹ã‚’æ·»ãˆã¦ãã ã•ã„ã€‚
3.  æŒ‡æ‘˜ãŒãªã„å ´åˆã¯ã€ã€ŒæŒ‡æ‘˜äº‹é …ãªã—ã€ã“ã®PRã¯å³ãƒãƒ¼ã‚¸OKã§ã™ã€ã¨ã ã‘å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼é‡ç‚¹é …ç›®ã€‘
* **ãƒã‚°**ï¼šè«–ç†çš„ãªèª¤ã‚Šã€äºˆæœŸã›ã¬ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã€ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å‡¦ç†ã®æ¼ã‚Œã€‚
* **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£**ï¼šæ½œåœ¨çš„ãªè„†å¼±æ€§ï¼ˆã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã€æƒ…å ±æ¼æ´©ã€èªå¯ã®æ¬ å¦‚ãªã©ï¼‰ã€‚
* **ä¿å®ˆæ€§**ï¼šã‚³ãƒ¼ãƒ‰ã®è¤‡é›‘æ€§ï¼ˆå¾ªç’°çš„è¤‡é›‘åº¦ãŒé«˜ã„éƒ¨åˆ†ï¼‰ã€å°†æ¥ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ãŒå¿…è¦ãªè¨­è¨ˆä¸Šã®å•é¡Œã€‚
* **å¯èª­æ€§**ï¼šå‘½åè¦å‰‡ã®é•åã€ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã®ä½¿ç”¨ã€ã‚³ãƒ¡ãƒ³ãƒˆä¸è¶³ã€‚
"""

# å¤‰æ›´å·®åˆ†(Diff)ã®å–å¾—
def get_diff(pr):
    files = pr.get_files()
    files_to_exclude = ['.env', '.env.local', 'secrets.yaml']
    raw_diff_text = ""
    for file in files:
        if file.filename.endswith(tuple(files_to_exclude)): continue
        if file.filename.endswith(('.lock', '.png', '.jpg', '.svg')): continue
        if not file.patch:
             continue
        raw_diff_text += f"File: {file.filename}\nDiff:\n{file.patch}\n\n"
    return raw_diff_text

def check_diff_size(pr, diff_text):
    # ç°¡å˜ãªãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ¦‚ç®— (æ–‡å­—æ•°/3ã§è¿‘ä¼¼)
    token_count = len(diff_text) // 3

    if token_count > CONFIG.flash_only_max_tokens:
        return False, token_count
    return True, token_count

def redact_secrets(diff_text: str) -> str:
    secret_patterns = [
        # --- å…±é€šï¼†ä¸»è¦ãªã‚¯ãƒ©ã‚¦ãƒ‰/ã‚µãƒ¼ãƒ“ã‚¹ ---
        r'(AKIA[0-9A-Z]{16,})',          # AWS Access Key ID
        r'(ghp_[0-9a-zA-Z]{36,})',       # GitHub Personal Access Token (ghp_)
        r'(ghs_[0-9a-zA-Z]{36,})',       # GitHub Scoped Token (ghs_)
        r'(xoxb-[0-9a-zA-Z-]+)',         # Slack Bot Token
        r'(sk-[0-9a-zA-Z]{32,})',        # OpenAI Key
        r'(?:rk|sk)_(?:live|test)_[0-9a-zA-Z]{24,}', # Stripe API Key
        r'(Bearer\s+[a-zA-Z0-9_-]+\.[a-zA-Z0-9_-]+\.[a-zA-Z0-9_-]+)', # JWT / Bearer Token
        r'(pk-[0-9a-zA-Z]{24,})',        # OpenAI/Anthropic Key
        r'(AIza[0-9A-Za-z-_]{35})',      # Google API Key
    ]
    # ç½®æ›å¾Œã®æ–‡å­—åˆ—
    REDACTED_TEXT = "[REDACTED_SECRET]"

    for pattern in secret_patterns:
        diff_text = re.sub(pattern, REDACTED_TEXT, diff_text)

    return diff_text

# å„AIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–¢æ•°
async def ask_gemini(diff_text):
    try:
        genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
        model = genai.GenerativeModel(
                CONFIG.gemini_model,
                system_instruction=SYSTEM_PROMPT
            )
        response = model.generate_content(f"ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰å·®åˆ†ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„:\n---\n{diff_text}\n---")
        return f"## â™Š Gemini\n{response.text}"
    except APIError as e:
        raise e
    except Exception as e:
        return f"## â™Š Gemini (Error)\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

async def ask_openai(diff_text):
    try:
        client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        response = client.chat.completions.create(
            model=CONFIG.gpt_model,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": f"ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰å·®åˆ†ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„:\n---\n{diff_text}\n---"}
            ]
        )
        return f"## ğŸ¤– ChatGPT\n{response.choices[0].message.content}"
    except OpenAI.APIError as e:
        raise e
    except Exception as e:
        return f"## ğŸ¤– ChatGPT (Error)\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

async def ask_claude(diff_text):
    try:
        client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
        message = client.messages.create(
            model=CONFIG.claude_model,
            max_tokens=2048,
            system=SYSTEM_PROMPT,
            messages=[
                {"role": "user", "content": f"ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰å·®åˆ†ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„:\n---\n{diff_text}\n---"}
            ]
        )
        return f"## ğŸ§  Claude\n{message.content[0].text}"
    except Anthropic.APIError as e:
        raise e
    except Exception as e:
        return f"## ğŸ§  Claude (Error)\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"

async def summarize_reviews(all_results):
    try:
        genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
        model_name = CONFIG.summarizer_model

        summarizer_model = genai.GenerativeModel(
            model_name,
            system_instruction="ã‚ãªãŸã¯ã€è¤‡æ•°ã®AIãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã®æ„è¦‹ã‚’çµ±åˆã—ã€æœ€ã‚‚é‡è¦ã§å„ªå…ˆåº¦ã®é«˜ã„æŒ‡æ‘˜äº‹é …ã ã‘ã‚’ã€é‡è¤‡ãªãä¸€ã¤ã®Markdownãƒªã‚¹ãƒˆã«ã¾ã¨ã‚ã‚‹ç·¨é›†é•·ã§ã™ã€‚ãƒˆãƒ¼ãƒ³ã¯å³ã—ãã€å†—é•·ãªè¡¨ç¾ã¯å…¨ã¦å‰Šé™¤ã—ã¦ãã ã•ã„ã€‚"
        )

        # 3ã¤ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’çµåˆ
        combined_text = "\n\n---\n\n".join(all_results)

        user_prompt = f"""ä»¥ä¸‹ã®3ã¤ã®AIãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’çµ±åˆã—ã€é‡è¤‡ã‚’æ’é™¤ã—ã€å…·ä½“çš„ãªæŒ‡æ‘˜ã‚’å„ªå…ˆåº¦é †ã«å†æ§‹æˆã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

ã€3ã¤ã®AIãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã€‘
---
{combined_text}
---
"""
        response = summarizer_model.generate_content(user_prompt)

        return f"# ğŸ‘‘ çµ±åˆAIãƒ¬ãƒ“ãƒ¥ãƒ¼ (by {model_name})\n\n{response.text}"

    except Exception as e:
        return f"# ğŸ‘‘ çµ±åˆAIãƒ¬ãƒ“ãƒ¥ãƒ¼ (Error)\nçµ±åˆå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}\n\n" + "\n\n---\n\n".join(all_results)

def create_final_comment(summary_report: str, individual_results: list[str]) -> str:
    final_comment = summary_report
    individual_section_content = "## ğŸ“„ å€‹åˆ¥AIãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœ (ç”Ÿã®å‡ºåŠ›)\n"
    individual_section_content += "ã“ã‚Œã‚‰ã®çµæœã‚’çµ±åˆAIãŒã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚çµ±åˆçµæœã«ä¸å‚™ãŒã‚ã‚‹å ´åˆã«ã”å‚ç…§ãã ã•ã„ã€‚\n\n"
    individual_section_content += "\n\n---\n\n".join(individual_results)
    collapsible_section = f"""
<details>
<summary>å€‹åˆ¥AIã®ç”Ÿãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’è¦‹ã‚‹ (ã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹)</summary>

{individual_section_content}

</details>
"""
    final_comment += "\n\n" + collapsible_section
    return final_comment

async def select_and_run_models(pr, diff_text: str, token_count: int) -> list[str]:
    """
    DIFFã‚µã‚¤ã‚ºã«åŸºã¥ãã€æœ€é©ãªAIãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã€éåŒæœŸã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    """
    if token_count <= CONFIG.small_diff_threshold:
        # é«˜æ€§èƒ½ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ3ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨ï¼‰
        print("INFO: 3ã¤ã®AIãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ä¸¦åˆ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œä¸­...")
        results_raw = await asyncio.gather(
            ask_gemini(diff_text),
            ask_openai(diff_text),
            ask_claude(diff_text),
            return_exceptions=True
        )

    elif token_count <= CONFIG.flash_only_max_tokens:
        # ã‚³ã‚¹ãƒˆå„ªå…ˆãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆGemini Flashã®ã¿ä½¿ç”¨ï¼‰
        print(f"INFO: DIFFã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚ ({token_count} tokens)ã€Geminiã®ã¿ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
        message = f"âš ï¸ **DIFFã‚µã‚¤ã‚º ({token_count} ãƒˆãƒ¼ã‚¯ãƒ³) ã®ãŸã‚ã€Geminiã®ã¿ã§ã‚³ã‚¹ãƒˆå„ªå…ˆãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿæ–½ã—ã¾ã—ãŸã€‚**"

        results_raw = await asyncio.gather(
            ask_gemini(diff_text),
            return_exceptions=True
        )
        results_raw.append(message)

    else:
        return []

    results = [r for r in results_raw if not isinstance(r, Exception)]

    # å…¨ã¦ã®AIãŒå¤±æ•—ã—ãŸå ´åˆã®å‡¦ç†
    if not results:
        return []

    return results

def validate_env_vars():
    required = ["GITHUB_TOKEN", "GEMINI_API_KEY", "OPENAI_API_KEY", "ANTHROPIC_API_KEY"]
    missing = [k for k in required if not os.getenv(k)]

    if missing:
        raise EnvironmentError(f"è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: ä»¥ä¸‹ã®å¿…é ˆç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™: {', '.join(missing)}")

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
async def main():
    validate_env_vars()

    # GitHubã®è¨­å®š
    g = Github(os.getenv("GITHUB_TOKEN"))
    repo = g.get_repo(os.getenv("GITHUB_REPOSITORY"))
    event_path = os.getenv("GITHUB_EVENT_PATH")
    with open(event_path) as f:
        event = json.load(f)

    if "pull_request" not in event:
        print("INFO: PRã‚¤ãƒ™ãƒ³ãƒˆã§ã¯ãªã„ãŸã‚AIãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        exit()

    pr_number = event["pull_request"]["number"]
    pr = repo.get_pull(pr_number)

    raw_diff_text = get_diff(pr)

    if not raw_diff_text:
        print("å¤‰æ›´å·®åˆ†ãŒæ¤œå‡ºã•ã‚Œãªã„ãŸã‚ã€å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return

    clean_diff = redact_secrets(raw_diff_text)
    is_ok, token_count = check_diff_size(pr, clean_diff)

    # DiffãŒå¤šã™ãã‚‹å ´åˆçµ‚äº†
    if not is_ok:
        pr.create_issue_comment(
            f"ğŸš¨ **è­¦å‘Š: DIFFã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ (ç´„ {token_count} ãƒˆãƒ¼ã‚¯ãƒ³)**\n"
            "AIãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ç²¾åº¦ã¨ã‚³ã‚¹ãƒˆæŠ‘åˆ¶ã®ãŸã‚ã€æ‰‹å‹•ã§ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"
        )
        return

    results = await select_and_run_models(pr, clean_diff, token_count)

    # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå®Ÿè¡Œã§ããªã‹ã£ãŸå ´åˆçµ‚äº†
    if not results:
        pr.create_issue_comment("ğŸš¨ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: å…¨ã¦ã®AIã‚µãƒ¼ãƒ“ã‚¹ã¸ã®æ¥ç¶šãŒå¤±æ•—ã—ã¾ã—ãŸã€‚APIã‚­ãƒ¼ã¾ãŸã¯ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    print("INFO: ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã®çµ±åˆå‡¦ç†ã‚’å®Ÿè¡Œä¸­...")
    summary_report = await summarize_reviews(results)

    final_comment = create_final_comment(summary_report, results)

    # éå»ã®ãƒœãƒƒãƒˆã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤ã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯
    print("INFO: æ—¢å­˜ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆã‚’å‰Šé™¤ä¸­...")
    comments = pr.get_issue_comments()
    HEADER_IDENTIFIER = "# ğŸ‘‘ çµ±åˆAIãƒ¬ãƒ“ãƒ¥ãƒ¼"

    for comment in comments:
        if comment.body and HEADER_IDENTIFIER in comment.body:
            try:
                comment.delete()
            except Exception as e:
                print(f"WARN: ã‚³ãƒ¡ãƒ³ãƒˆå‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ (ç„¡è¦–): {e}")

    # ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿
    pr.create_issue_comment(final_comment)
    print("SUCCESS: ãƒ¬ãƒ“ãƒ¥ãƒ¼å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    asyncio.run(main())
